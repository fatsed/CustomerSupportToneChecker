{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnJaDIEHOYZ6W3x+Pthgvi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatsed/CustomerSupportToneChecker/blob/main/notebooks/02_ToneDetection_api_ui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1-dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CjJarOHRrUKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fatsed/CustomerSupportToneChecker.git"
      ],
      "metadata": {
        "id": "lEBYkFyY0Utj",
        "outputId": "6bee9a23-6476-4b96-cfed-eadb05e3ff4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CustomerSupportToneChecker'...\n",
            "remote: Enumerating objects: 90, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 90 (delta 36), reused 37 (delta 12), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (90/90), 145.11 KiB | 1.59 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CustomerSupportToneChecker/notebooks"
      ],
      "metadata": {
        "id": "hsYwz9Op0YBu",
        "outputId": "c3208cb0-a38e-4b6a-f6a7-ede9b3e8c6a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CustomerSupportToneChecker/notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "import pandas as pd\n",
        "csv_path = \"../dataset/tone_dataset.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "print(\"Shape:\", df.shape)\n",
        "print(df.head())\n",
        "print(df[\"label\"].value_counts())"
      ],
      "metadata": {
        "id": "_AQoW4QZ0RiB",
        "outputId": "f85b0c95-2c2a-4d79-ef7a-272c395ebf54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (300, 3)\n",
            "  id                                               text   label\n",
            "0  1  Ø³Ù„Ø§Ù… ÙˆÙ‚Øª Ø¨Ø®ÛŒØ±. Ù…ÛŒâ€ŒØ®ÙˆØ§Ø³ØªÙ… ÙˆØ¶Ø¹ÛŒØª Ø³ÙØ§Ø±Ø´ Ø´Ù…Ø§Ø±Ù‡ Û±Û²Û³...  polite\n",
            "1  2  Ø³Ù„Ø§Ù… Ùˆ Ø¹Ø±Ø¶ Ø§Ø¯Ø¨. Ù„Ø·ÙØ§Ù‹ Ø²Ù…Ø§Ù† ØªÙ‚Ø±ÛŒØ¨ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ø³ØªÙ‡ Ù…...  polite\n",
            "2  3  Ø¨Ø§ Ø³Ù„Ø§Ù…. Ù…Ù…Ù†ÙˆÙ† Ù…ÛŒâ€ŒØ´Ù… Ø§Ú¯Ø± Ú©Ø¯ Ø±Ù‡Ú¯ÛŒØ±ÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ù†Ø¯...  polite\n",
            "3  4  Ø±ÙˆØ²ØªÙˆÙ† Ø¨Ø®ÛŒØ±. Ø§Ù…Ú©Ø§Ù†Ø´ Ù‡Ø³Øª ÙˆØ¶Ø¹ÛŒØª Ù…Ø±Ø³ÙˆÙ„Ù‡ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ ...  polite\n",
            "4  5  Ø³Ù„Ø§Ù…. Ù…Ù…Ù†ÙˆÙ† Ù…ÛŒâ€ŒØ´Ù… Ø§Ú¯Ø± Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯ Ú†Ø·ÙˆØ± Ù…ÛŒâ€ŒØªÙˆ...  polite\n",
            "label\n",
            "polite         100\n",
            "semi_polite    100\n",
            "impolite       100\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels to numeric (label_id)\n",
        "label_map = {\n",
        "    \"polite\": 0,\n",
        "    \"semi_polite\": 1,\n",
        "    \"impolite\": 2\n",
        "}\n",
        "df[\"label_id\"] = df[\"label\"].map(label_map)\n",
        "print(df[[\"id\", \"text\", \"label\", \"label_id\"]].head())\n",
        "print(\"\\nEncoded label counts:\")\n",
        "print(df[\"label_id\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2HzmOCbHZls",
        "outputId": "50f75c8b-d43f-402a-9cb6-62ba4ec7ef62"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  id                                               text   label  label_id\n",
            "0  1  Ø³Ù„Ø§Ù… ÙˆÙ‚Øª Ø¨Ø®ÛŒØ±. Ù…ÛŒâ€ŒØ®ÙˆØ§Ø³ØªÙ… ÙˆØ¶Ø¹ÛŒØª Ø³ÙØ§Ø±Ø´ Ø´Ù…Ø§Ø±Ù‡ Û±Û²Û³...  polite         0\n",
            "1  2  Ø³Ù„Ø§Ù… Ùˆ Ø¹Ø±Ø¶ Ø§Ø¯Ø¨. Ù„Ø·ÙØ§Ù‹ Ø²Ù…Ø§Ù† ØªÙ‚Ø±ÛŒØ¨ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ø³ØªÙ‡ Ù…...  polite         0\n",
            "2  3  Ø¨Ø§ Ø³Ù„Ø§Ù…. Ù…Ù…Ù†ÙˆÙ† Ù…ÛŒâ€ŒØ´Ù… Ø§Ú¯Ø± Ú©Ø¯ Ø±Ù‡Ú¯ÛŒØ±ÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ù†Ø¯...  polite         0\n",
            "3  4  Ø±ÙˆØ²ØªÙˆÙ† Ø¨Ø®ÛŒØ±. Ø§Ù…Ú©Ø§Ù†Ø´ Ù‡Ø³Øª ÙˆØ¶Ø¹ÛŒØª Ù…Ø±Ø³ÙˆÙ„Ù‡ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ ...  polite         0\n",
            "4  5  Ø³Ù„Ø§Ù…. Ù…Ù…Ù†ÙˆÙ† Ù…ÛŒâ€ŒØ´Ù… Ø§Ú¯Ø± Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯ Ú†Ø·ÙˆØ± Ù…ÛŒâ€ŒØªÙˆ...  polite         0\n",
            "\n",
            "Encoded label counts:\n",
            "label_id\n",
            "0    100\n",
            "1    100\n",
            "2    100\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2-Preprocessing"
      ],
      "metadata": {
        "id": "JLFWERWHsmgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim python-crfsuite fasttext flashtext && pip install hazm --no-deps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RuNCZH3jHo30",
        "outputId": "47f58b59-db39-4716-9fd0-31b8e2190254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting python-crfsuite\n",
            "  Downloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flashtext\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "Building wheels for collected packages: fasttext, flashtext\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hazm import Normalizer, word_tokenize, stopwords_list\n",
        "import re\n",
        "\n",
        "normalizer = Normalizer()\n",
        "stopwords = set(stopwords_list())\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    text = str(text)\n",
        "\n",
        "    # 1) Normalize\n",
        "    text = normalizer.normalize(text)\n",
        "\n",
        "    # 2) Remove English letters and numbers (optional but cleaner)\n",
        "    text = re.sub(r\"[A-Za-z0-9Û°-Û¹]\", \" \", text)\n",
        "\n",
        "    # 3) Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # 4) Remove stopwords + very short tokens\n",
        "    tokens = [t for t in tokens if t not in stopwords and len(t) > 1]\n",
        "\n",
        "    # 5) âš ï¸ NO STEMMING, NO LEMMATIZATION\n",
        "    # (Ú†ÙˆÙ† Ø¨Ø§Ø¹Ø« Ø®Ø±Ø§Ø¨ Ø´Ø¯Ù† Ú©Ù„Ù…Ù‡â€ŒÙ‡Ø§ Ù…ÛŒâ€ŒØ´Ù‡)\n",
        "\n",
        "    return \" \".join(tokens)\n"
      ],
      "metadata": {
        "id": "BPF5j0K6H7tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text_clean\"] = df[\"text\"].apply(clean_text)\n",
        "print(\"Ù†Ù…ÙˆÙ†Ù‡ Ù‚Ø¨Ù„ Ùˆ Ø¨Ø¹Ø¯ Ø§Ø² Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´:\")\n",
        "df[[\"text\", \"text_clean\"]].head(10)\n"
      ],
      "metadata": {
        "id": "_yJfOLz0Izxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save preprocessed dataset\n",
        "preprocessed_csv_path = \"../dataset/tone_dataset_preprocessed.csv\"\n",
        "df.to_csv(preprocessed_csv_path, index=False, encoding=\"utf-8-sig\")\n",
        "print(\"Preprocessed CSV saved at:\", preprocessed_csv_path)\n",
        "print(\"Columns:\", df.columns.tolist())"
      ],
      "metadata": {
        "id": "YBn0qyo-JAdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3-Feature Extraction"
      ],
      "metadata": {
        "id": "kjDsW4a6sqWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[\"text_clean\"]\n",
        "y = df[\"label_id\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,       # 20Ùª Ø¨Ø±Ø§ÛŒ ØªØ³Øª\n",
        "    stratify=y,          # Ø­ÙØ¸ Ù†Ø³Ø¨Øª Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(X_train))\n",
        "print(\"Test size:\", len(X_test))\n",
        "print(\"Label distribution in train:\")\n",
        "print(y_train.value_counts())"
      ],
      "metadata": {
        "id": "wvV1gkXfY1z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),   # uni-gram + bi-gram\n",
        "    min_df=1,             # Ø­Ø¯Ø§Ù‚Ù„ ØªØ¹Ø¯Ø§Ø¯ Ø¸Ø§Ù‡Ø± Ø´Ø¯Ù†\n",
        "    # Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ù†ØªØ±Ù„ Ø§Ø¨Ø¹Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø§Ø² max_features Ù‡Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØŒ Ù…Ø«Ù„Ø§Ù‹:\n",
        "    # max_features=5000\n",
        ")\n",
        "\n",
        "# fit ÙÙ‚Ø· Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ train\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "\n",
        "# transform Ø±ÙˆÛŒ test Ø¨Ø§ Ù‡Ù…ÙˆÙ† ÙˆØ§Ú˜Ù‡â€ŒÙ†Ø§Ù…Ù‡\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "print(\"TF-IDF train shape:\", X_train_tfidf.shape)\n",
        "print(\"TF-IDF test shape:\", X_test_tfidf.shape)\n"
      ],
      "metadata": {
        "id": "AX1DLW2waF89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = tfidf.get_feature_names_out()\n",
        "print(\"Total features:\", len(feature_names))\n",
        "print(\"Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ú†Ù†Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒ Ø§ÙˆÙ„:\")\n",
        "print(feature_names[:30])"
      ],
      "metadata": {
        "id": "aXUSM_-YaUNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4-Model Training"
      ],
      "metadata": {
        "id": "YAQQm5-0swtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4- Model Training (Linear SVM) - BEHTARE TOYE ADEHAYE KOTAH"
      ],
      "metadata": {
        "id": "qEgXqPLta8VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 4.1 Train Linear SVM =====\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "svm_model = LinearSVC()\n",
        "\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"âœ” Ù…Ø¯Ù„ SVM Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯.\")"
      ],
      "metadata": {
        "id": "6q1jvScWbGRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 4.2 Make predictions =====\n",
        "y_pred = svm_model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Predictions done.\")"
      ],
      "metadata": {
        "id": "_RUR6JJcbOsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 4.3 Evaluation =====\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {acc:.4f}\\n\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"polite\",\"semi_polite\",\"impolite\"]))"
      ],
      "metadata": {
        "id": "92PiyQPbiLFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 4.4 Confusion Matrix =====\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\",\n",
        "            xticklabels=[\"polite\",\"semi_polite\",\"impolite\"],\n",
        "            yticklabels=[\"polite\",\"semi_polite\",\"impolite\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix - Tone Classification (SVM)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XDWQRhGDiTJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.5 - Train & Compare Multiple Models (SVM / LR / RF / DT)\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§\n",
        "models_dict = {\n",
        "    \"SVM (LinearSVC)\": LinearSVC(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42)\n",
        "}"
      ],
      "metadata": {
        "id": "wKmvpGe9ibVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def train_and_evaluate(model, X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    ÛŒÚ© Ù…Ø¯Ù„ Ø§Ø³Ú©ÛŒÚ©ÛŒØªâ€ŒÙ„Ø±Ù† Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯ØŒ\n",
        "    Ø±ÙˆÛŒ train ÙÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ\n",
        "    Ø±ÙˆÛŒ test Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ\n",
        "    Ùˆ accuracy / precision / recall / f1 (macro) Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.\n",
        "    \"\"\"\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        y_test, y_pred, average=\"macro\", zero_division=0\n",
        "    )\n",
        "\n",
        "    return model, acc, precision, recall, f1"
      ],
      "metadata": {
        "id": "rgg43CZMpmcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "results = []\n",
        "trained_models = {}   # Ø§ÛŒÙ†Ø¬Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡ Ø±Ø§ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ… Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± UI\n",
        "\n",
        "for name, model in models_dict.items():\n",
        "    print(f\"ğŸ”¹ Training model: {name} ...\")\n",
        "    fitted_model, acc, prec, rec, f1 = train_and_evaluate(\n",
        "        model, X_train_tfidf, y_train, X_test_tfidf, y_test\n",
        "    )\n",
        "\n",
        "    trained_models[name] = fitted_model  # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ø¨Ø¹Ø¯Ø§Ù‹\n",
        "\n",
        "    results.append({\n",
        "        \"model\": name,\n",
        "        \"accuracy\": acc,\n",
        "        \"precision_macro\": prec,\n",
        "        \"recall_macro\": rec,\n",
        "        \"f1_macro\": f1\n",
        "    })\n",
        "\n",
        "# Ø³Ø§Ø®Øª DataFrame Ù†ØªØ§ÛŒØ¬\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by=\"accuracy\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nğŸ“Š Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§:\")\n",
        "results_df"
      ],
      "metadata": {
        "id": "OBkF1b_apofa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.6 - Active model selector\n",
        "\n",
        "# Ù¾ÛŒØ´â€ŒÙØ±Ø¶: SVM Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù…Ø¯Ù„ ÙØ¹Ø§Ù„ Ù…ÛŒâ€ŒÚ¯Ø°Ø§Ø±ÛŒÙ…\n",
        "active_model_name = \"Logistic Regression\"\n",
        "active_model = trained_models[active_model_name]\n",
        "\n",
        "print(\"Ù…Ø¯Ù„ ÙØ¹Ø§Ù„ ÙØ¹Ù„ÛŒ:\", active_model_name)"
      ],
      "metadata": {
        "id": "LkNZBB22pv3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tone(text: str, model_name: str = None):\n",
        "    \"\"\"\n",
        "    Ø§Ú¯Ø± model_name Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯ØŒ Ø§Ø² Ø¢Ù† Ù…Ø¯Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….\n",
        "    Ø§Ú¯Ø± Ù†Ù‡ØŒ Ø§Ø² active_model Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
        "    \"\"\"\n",
        "    if model_name is None:\n",
        "        model = active_model\n",
        "        name = active_model_name\n",
        "    else:\n",
        "        model = trained_models.get(model_name, active_model)\n",
        "        name = model_name\n",
        "\n",
        "    text_clean = clean_text(text)\n",
        "    x_vec = tfidf.transform([text_clean])\n",
        "    pred_id = model.predict(x_vec)[0]\n",
        "\n",
        "    label_en = id2label[pred_id]\n",
        "    label_fa = label2fa[label_en]\n",
        "\n",
        "    return name, label_en, label_fa"
      ],
      "metadata": {
        "id": "S5dZH_ROq50L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = \"Ø§ÛŒÙ† Ú†Ù‡ ÙˆØ¶Ø¹Ø´Ù‡ØŸ Ú†Ù†Ø¯ Ø±ÙˆØ²Ù‡ Ù…Ø¹Ø·Ù„ Ø³ÙØ§Ø±Ø´Ù… Ù‡Ø³ØªÙ…!\"\n",
        "for name in trained_models.keys():\n",
        "    m_name, en, fa = predict_tone(test_text, model_name=name)\n",
        "    print(f\"Ù…Ø¯Ù„: {m_name} â†’ {en} / {fa}\")"
      ],
      "metadata": {
        "id": "Ldb4zRtFq8i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5-Evaluation"
      ],
      "metadata": {
        "id": "eGVMP7MYs0pY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation & Error Analysis"
      ],
      "metadata": {
        "id": "jxFKWh4LiajV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 5.1 Build test_df with true & predicted labels =====\n",
        "# Ù†Ú¯Ø§Ø´Øª Ø¹Ø¯Ø¯ Ø¨Ù‡ Ø§Ø³Ù… Ú©Ù„Ø§Ø³\n",
        "id2label = {\n",
        "    0: \"polite\",\n",
        "    1: \"semi_polite\",\n",
        "    2: \"impolite\"\n",
        "}\n",
        "# Ø§Ù†ØªØ®Ø§Ø¨ Ø³Ø·Ø±Ù‡Ø§ÛŒ ØªØ³Øª Ø§Ø² df Ø§ØµÙ„ÛŒ (Ø¨Ø± Ø§Ø³Ø§Ø³ index)\n",
        "test_df = df.loc[X_test.index].copy()\n",
        "# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ø±Ú†Ø³Ø¨ ÙˆØ§Ù‚Ø¹ÛŒ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒØ´Ø¯Ù‡\n",
        "test_df[\"y_true\"] = y_test.values\n",
        "test_df[\"y_pred\"] = y_pred\n",
        "\n",
        "test_df[\"true_label\"] = test_df[\"y_true\"].map(id2label)\n",
        "test_df[\"pred_label\"] = test_df[\"y_pred\"].map(id2label)\n",
        "\n",
        "print(test_df[[\"id\", \"text\", \"true_label\", \"pred_label\"]].head(10))"
      ],
      "metadata": {
        "id": "ZDo7qKI6jeHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 5.2 Extract misclassified examples =====\n",
        "errors = test_df[test_df[\"y_true\"] != test_df[\"y_pred\"]].copy()\n",
        "\n",
        "print(\"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª:\", len(test_df))\n",
        "print(\"ØªØ¹Ø¯Ø§Ø¯ Ø®Ø·Ø§Ù‡Ø§:\", len(errors))\n",
        "print(\"Ù†Ø±Ø® Ø®Ø·Ø§:\", len(errors) / len(test_df))\n",
        "\n",
        "# Ú†Ù†Ø¯ ØªØ§ Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø² Ø®Ø·Ø§Ù‡Ø§\n",
        "errors[[\"id\", \"text\", \"true_label\", \"pred_label\"]].head(15)\n"
      ],
      "metadata": {
        "id": "yGIWoKW6jvW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 5.3 Group errors by (true_label, pred_label) =====\n",
        "\n",
        "error_groups = errors.groupby([\"true_label\", \"pred_label\"]).size().reset_index(name=\"count\")\n",
        "print(error_groups)"
      ],
      "metadata": {
        "id": "xRrUcpqfj2Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø®Ø·Ù„Ø§ Ø¨Ø±Ø§ÛŒ impolite"
      ],
      "metadata": {
        "id": "GF9tvNYvj-FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 5.4 Show some typical errors for each confusion case =====\n",
        "\n",
        "def show_errors(true_label, pred_label, n=5):\n",
        "    subset = errors[(errors[\"true_label\"] == true_label) &\n",
        "                    (errors[\"pred_label\"] == pred_label)]\n",
        "    print(f\"\\n=== ÙˆØ§Ù‚Ø¹ÛŒ: {true_label} | Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ: {pred_label} | ØªØ¹Ø¯Ø§Ø¯: {len(subset)} ===\")\n",
        "    for i, row in subset.head(n).iterrows():\n",
        "        print(\"â€¢ Ù…ØªÙ†:\", row[\"text\"])\n",
        "        print(\"---\")\n",
        "\n",
        "# Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ (Ù‡Ø± Ú©Ø¯ÙˆÙ… Ø§Ú¯Ø± Ø®Ø·Ø§ Ø¯Ø§Ø´Øª)\n",
        "show_errors(\"polite\", \"semi_polite\", n=5)\n",
        "show_errors(\"semi_polite\", \"polite\", n=5)\n",
        "show_errors(\"semi_polite\", \"impolite\", n=5)\n",
        "show_errors(\"impolite\", \"semi_polite\", n=5)"
      ],
      "metadata": {
        "id": "XKy_jDq2kHXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "!!!Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ \"Ø§ÛŒÙ† Ø¬Ù…Ù„Ù‡ Ø§Ø² Ù†Ø¸Ø± Ø§Ù†Ø³Ø§Ù†ÛŒ Ù†ÛŒÙ…Ù‡â€ŒÙ…ÙˆØ¯Ø¨ Ø§Ø³ØªØŒ Ø§Ù…Ø§ Ù…Ø¯Ù„ Ø¢Ù† Ø±Ø§ Ù…ÙˆØ¯Ø¨ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡Ø› Ú†ÙˆÙ† ÙˆØ§Ú˜Ú¯Ø§Ù† Ù…ÙˆØ¯Ø¨Ø§Ù†Ù‡ (Â«Ù„Ø·ÙØ§Ù‹Â»ØŒ Â«Ù…Ù…Ù†ÙˆÙ†Â») Ø¯Ø± Ù…ØªÙ† ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.\""
      ],
      "metadata": {
        "id": "qXygpK9fktbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 5.5 Normalized confusion matrix (row-wise) =====\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_norm = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm_norm, annot=True, cmap=\"Blues\", fmt=\".2f\",\n",
        "            xticklabels=[\"polite\",\"semi_polite\",\"impolite\"],\n",
        "            yticklabels=[\"polite\",\"semi_polite\",\"impolite\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Normalized Confusion Matrix (Row-wise)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T8Whuvdekz8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6-UI\n"
      ],
      "metadata": {
        "id": "kzRUoPGZs1eZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6- Inference & Simple UI\n",
        "# Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ ÛŒÚ© ØªØ§Ø¨Ø¹ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù„Ø­Ù† Ù…ÛŒâ€ŒØ³Ø§Ø²ÛŒÙ…\n",
        "# Ùˆ ÛŒÚ© Ø±Ø§Ø¨Ø· Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯."
      ],
      "metadata": {
        "id": "IBlQfTkZj9lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 6.1 Label maps =====\n",
        "\n",
        "id2label = {\n",
        "    0: \"polite\",\n",
        "    1: \"semi_polite\",\n",
        "    2: \"impolite\"\n",
        "}\n",
        "\n",
        "label2fa = {\n",
        "    \"polite\": \"Ù…ÙˆØ¯Ø¨Ø§Ù†Ù‡\",\n",
        "    \"semi_polite\": \"Ù†ÛŒÙ…Ù‡â€ŒÙ…ÙˆØ¯Ø¨Ø§Ù†Ù‡\",\n",
        "    \"impolite\": \"ØºÛŒØ±Ù…ÙˆØ¯Ø¨Ø§Ù†Ù‡\"\n",
        "}"
      ],
      "metadata": {
        "id": "HvaiP-LClS-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 6.2 Define predict_tone function =====\n",
        "def predict_tone(text: str):\n",
        "    \"\"\"\n",
        "    ÙˆØ±ÙˆØ¯ÛŒ: Ù…ØªÙ† Ø®Ø§Ù… Ù¾ÛŒØ§Ù… Ù…Ø´ØªØ±ÛŒ (ÙØ§Ø±Ø³ÛŒ)\n",
        "    Ø®Ø±ÙˆØ¬ÛŒ:\n",
        "      - label_en: ÛŒÚ©ÛŒ Ø§Ø² ['polite', 'semi_polite', 'impolite']\n",
        "      - label_fa: Ù…Ø¹Ø§Ø¯Ù„ ÙØ§Ø±Ø³ÛŒ (Ù…ÙˆØ¯Ø¨Ø§Ù†Ù‡ / Ù†ÛŒÙ…Ù‡â€ŒÙ…ÙˆØ¯Ø¨Ø§Ù†Ù‡ / ØºÛŒØ±Ù…ÙˆØ¯Ø¨Ø§Ù†Ù‡)\n",
        "    \"\"\"\n",
        "    # 1) Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ù‡Ù…ÙˆÙ† ØªØ§Ø¨Ø¹ clean_text\n",
        "    text_clean = clean_text(text)\n",
        "\n",
        "    # 2) ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ TF-IDF\n",
        "    x_vec = tfidf.transform([text_clean])\n",
        "\n",
        "    # 3) Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§ Ù…Ø¯Ù„ SVM\n",
        "    pred_id = svm_model.predict(x_vec)[0]\n",
        "\n",
        "    # 4) Ù†Ú¯Ø§Ø´Øª Ø¨Ù‡ Ù„ÛŒØ¨Ù„ Ù…ØªÙ†ÛŒ\n",
        "    label_en = id2label[pred_id]\n",
        "    label_fa = label2fa[label_en]\n",
        "\n",
        "    return label_en, label_fa"
      ],
      "metadata": {
        "id": "1WS4GDGPlU8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 6.3 Quick tests =====\n",
        "\n",
        "samples = [\n",
        "    \"Ø³Ù„Ø§Ù… ÙˆÙ‚Øª Ø¨Ø®ÛŒØ±ØŒ Ù…ÛŒØ´Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø³ÙØ§Ø±Ø´Ù… Ø±Ùˆ Ø¨Ú¯ÛŒØ¯ØŸ\",\n",
        "    \"Ú†Ù†Ø¯ Ø±ÙˆØ²Ù‡ Ù…Ù†ØªØ¸Ø±Ù…ØŒ Ù„Ø·ÙØ§Ù‹ Ø¨Ú¯ÛŒØ¯ Ø³ÙØ§Ø±Ø´ Ø§Ù„Ø§Ù† Ú©Ø¬Ø§Ø³Øª.\",\n",
        "    \"Ø§ÛŒÙ† Ú†Ù‡ ÙˆØ¶Ø¹Ø´Ù‡ØŸ Ú†Ù†Ø¯ Ø¨Ø§Ø± Ù¾ÛŒØ§Ù… Ø¯Ø§Ø¯Ù… Ù‡ÛŒÚ†Ú©Ø³ Ø¬ÙˆØ§Ø¨ Ù†Ù…ÛŒØ¯Ù‡!\"\n",
        "]\n",
        "\n",
        "for s in samples:\n",
        "    en, fa = predict_tone(s)\n",
        "    print(\"Ù…ØªÙ†:\", s)\n",
        "    print(\" â†’ Ù„Ø­Ù† (EN):\", en, \"| (FA):\", fa)\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "Dg7b58wSlZ61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 6.4 Simple CLI loop for interactive testing =====\n",
        "\n",
        "print(\"Ø³ÛŒØ³ØªÙ… ØªØ´Ø®ÛŒØµ Ù„Ø­Ù† Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…Ø´ØªØ±ÛŒ\")\n",
        "print(\"Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ØŒ ÙÙ‚Ø· q Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "while True:\n",
        "    msg = input(\"Ù¾ÛŒØ§Ù… Ù…Ø´ØªØ±ÛŒ: \")\n",
        "    if msg.strip().lower() == \"q\":\n",
        "        print(\"Ø®Ø±ÙˆØ¬ Ø§Ø² Ø³ÛŒØ³ØªÙ….\")\n",
        "        break\n",
        "\n",
        "    en, fa = predict_tone(msg)\n",
        "    print(\"Ù„Ø­Ù† ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡:\")\n",
        "    print(\"  - Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ:\", en)\n",
        "    print(\"  - ÙØ§Ø±Ø³ÛŒ  :\", fa)\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "kuJ65g5ulgOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7- Gradio UI (API Level)"
      ],
      "metadata": {
        "id": "sfuppziYljcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7- Gradio UI (API Level)\n",
        "\n",
        "!pip install gradio -q\n",
        "\n",
        "import gradio as gr\n",
        "import requests\n"
      ],
      "metadata": {
        "id": "SRFXpHDurz8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 7.2 HuggingFace API setup (temporary KEY handling) =====\n",
        "\n",
        "HF_API_URL = \"https://api-inference.huggingface.co/models/HooshvareLab/bert-fa-base-uncased-sentiment-snappfood\"\n",
        "HF_API_KEY = \"\"  # Ú©Ù„ÛŒØ¯ Ù…ÙˆÙ‚Øª â€“ Ø§Ø² Ø¨ÛŒØ±ÙˆÙ† Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´Ù‡ Ùˆ Ø¢Ù¾Ø¯ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "\n",
        "def set_hf_key(new_key: str):\n",
        "    \"\"\"\n",
        "    Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ú©Ù„ÛŒØ¯ Ù…ÙˆÙ‚Øª HuggingFace.\n",
        "    \"\"\"\n",
        "    global HF_API_KEY\n",
        "    HF_API_KEY = new_key.strip()\n",
        "    if HF_API_KEY:\n",
        "        return \"âœ… Ú©Ù„ÛŒØ¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯.\"\n",
        "    else:\n",
        "        return \"âš ï¸ Ú©Ù„ÛŒØ¯ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ ÛŒÚ© ØªÙˆÚ©Ù† Ù…Ø¹ØªØ¨Ø± ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.\"\n",
        "\n",
        "\n",
        "def hf_predict_raw(text: str):\n",
        "    \"\"\"\n",
        "    ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… API Ù‡Ø§Ú¯ÛŒÙ†Ú¯â€ŒÙÛŒØ³.\n",
        "    Ø®Ø±ÙˆØ¬ÛŒ Ø®Ø§Ù… Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ (Ù„ÛŒØ¨Ù„â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯Ø´).\n",
        "    \"\"\"\n",
        "    if not HF_API_KEY:\n",
        "        return None, \"âŒ Ù‡ÛŒÚ† API Key ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡. Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ Ú©Ù„ÛŒØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ùˆ Update Ø±Ø§ Ø¨Ø²Ù†ÛŒØ¯.\"\n",
        "\n",
        "    headers = {\"Authorization\": f\"Bearer {HF_API_KEY}\"}\n",
        "    payload = {\"inputs\": text}\n",
        "\n",
        "    try:\n",
        "        response = requests.post(HF_API_URL, headers=headers, json=payload, timeout=30)\n",
        "        if response.status_code != 200:\n",
        "            return None, f\"âŒ Ø®Ø·Ø§ Ø§Ø² Ø³Ù…Øª HuggingFace: {response.status_code} - {response.text}\"\n",
        "        data = response.json()\n",
        "        return data, None\n",
        "    except Exception as e:\n",
        "        return None, f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ API: {e}\""
      ],
      "metadata": {
        "id": "Cm2tvwRcr1aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_hf_to_tone(hf_output):\n",
        "    \"\"\"\n",
        "    ÙØ±Ø¶: Ù…Ø¯Ù„ Ø®Ø±ÙˆØ¬ÛŒ POSITIVE / NEGATIVE / NEUTRAL Ø¯Ø§Ø±Ø¯.\n",
        "    Ù…Ø§ Ø§ÛŒÙ†â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ polite / semi_polite / impolite Ù†Ú¯Ø§Ø´Øª Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Ø³Ø§Ø®ØªØ§Ø± Ù…Ø¹Ù…ÙˆÙ„ Ø®Ø±ÙˆØ¬ÛŒ: [[{\"label\": \"...\", \"score\": ...}, ...]]\n",
        "        first = hf_output[0][0]\n",
        "        label = first[\"label\"].upper()\n",
        "    except Exception:\n",
        "        return \"semi_polite\", \"Ù†ÛŒÙ…Ù‡â€ŒÙ…ÙˆØ¯Ø¨Ø§Ù†Ù‡\"  # Ø­Ø§Ù„Øª Ø§Ù…Ù†\n",
        "\n",
        "    if \"POSITIVE\" in label:\n",
        "        return \"polite\", \"Ù…ÙˆØ¯Ø¨Ø§Ù†Ù‡\"\n",
        "    elif \"NEGATIVE\" in label:\n",
        "        return \"impolite\", \"ØºÛŒØ±Ù…ÙˆØ¯Ø¨Ø§Ù†Ù‡\"\n",
        "    else:\n",
        "        return \"semi_polite\", \"Ù†ÛŒÙ…Ù‡â€ŒÙ…ÙˆØ¯Ø¨Ø§Ù†Ù‡\""
      ],
      "metadata": {
        "id": "GRVwbdA_sA3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tone_hf(text: str):\n",
        "    hf_data, error = hf_predict_raw(text)\n",
        "    if error:\n",
        "        return \"HuggingFace API\", error\n",
        "\n",
        "    en, fa = map_hf_to_tone(hf_data)\n",
        "    return \"HuggingFace API\", f\"Ù„Ø­Ù† (EN): {en} | (FA): {fa}\""
      ],
      "metadata": {
        "id": "928cF7S5sBeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 7.3 Main Gradio inference function =====\n",
        "\n",
        "def gradio_predict(user_text, task, model_choice):\n",
        "    if not user_text or user_text.strip() == \"\":\n",
        "        return \"Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…ØªÙ† ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.\"\n",
        "\n",
        "    # ÙØ¹Ù„Ø§Ù‹ ÙÙ‚Ø· Classification (ØªØ´Ø®ÛŒØµ Ù„Ø­Ù†) Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡\n",
        "    if task != \"Classification (Tone Detection)\":\n",
        "        return \"âš ï¸ ÙØ¹Ù„Ø§Ù‹ ÙÙ‚Ø· Ø¨Ø®Ø´ Â«ØªØ´Ø®ÛŒØµ Ù„Ø­Ù† Ù¾ÛŒØ§Ù… Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒÂ» Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª.\"\n",
        "\n",
        "    # Ø§Ú¯Ø± Ù…Ø¯Ù„ HuggingFace Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡:\n",
        "    if model_choice == \"HuggingFace (API)\":\n",
        "        model_name, result = predict_tone_hf(user_text)\n",
        "        return f\"[{model_name}] â†’ {result}\"\n",
        "\n",
        "    # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ (SVM, LR, RF, DT)\n",
        "    model = trained_models.get(model_choice)\n",
        "    if model is None:\n",
        "        return \"âŒ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.\"\n",
        "\n",
        "    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² clean_text + tfidf + Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡\n",
        "    text_clean = clean_text(user_text)\n",
        "    vec = tfidf.transform([text_clean])\n",
        "    pred_id = model.predict(vec)[0]\n",
        "\n",
        "    label_en = id2label[pred_id]\n",
        "    label_fa = label2fa[label_en]\n",
        "\n",
        "    return f\"Ù…Ø¯Ù„: {model_choice}\\nÙ„Ø­Ù† (EN): {label_en}\\nÙ„Ø­Ù† (FA): {label_fa}\""
      ],
      "metadata": {
        "id": "XzngzHGwsCwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 7.4 Gradio Blocks UI =====\n",
        "\n",
        "task_options = [\n",
        "    \"Classification (Tone Detection)\",\n",
        "    \"Spam Detection (Coming Soon)\",\n",
        "    \"Translation (Coming Soon)\"\n",
        "]\n",
        "\n",
        "model_options = list(trained_models.keys()) + [\"HuggingFace (API)\"]\n",
        "\n",
        "with gr.Blocks(title=\"Special Topics - NLP Project\") as demo:\n",
        "    # State Ø¨Ø±Ø§ÛŒ Ú©Ù†ØªØ±Ù„ Ù†Ù…Ø§ÛŒØ´ ØµÙØ­Ù‡â€ŒÙ‡Ø§\n",
        "    show_main = gr.State(False)\n",
        "\n",
        "    # ---------- ØµÙØ­Ù‡ Û±: Welcome ----------\n",
        "    with gr.Column(visible=True) as page1:\n",
        "        gr.Markdown(\"## Ø¯Ø±Ø³ Ù…Ø¨Ø§Ø­Ø« ÙˆÛŒÚ˜Ù‡ â€“ Ø§Ø³ØªØ§Ø¯ Ø²Ø§ØºØ±ÛŒ\")\n",
        "        gr.Markdown(\"### Ù¾Ø±ÙˆÚ˜Ù‡: Ø³ÛŒØ³ØªÙ… ØªØ´Ø®ÛŒØµ Ù„Ø­Ù† Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…Ø´ØªØ±ÛŒ\")\n",
        "        gr.Markdown(\"**Ù†Ø§Ù… Ø¯Ø§Ù†Ø´Ø¬Ùˆ: ÙØ§Ø·Ù…Ù‡ ØµØ¯ÙŠÙ‚ÛŒâ€ŒØ²Ø§Ø¯Ù‡**\")\n",
        "        gr.Markdown(\"Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡ØŒ Ø±ÙˆÛŒ Ø¯Ú©Ù…Ù‡ Ø²ÛŒØ± Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯.\")\n",
        "        btn_next = gr.Button(\"Next â–¶ï¸\")\n",
        "\n",
        "    # ---------- ØµÙØ­Ù‡ Û²: UI Ø§ØµÙ„ÛŒ ----------\n",
        "    with gr.Column(visible=False) as page2:\n",
        "        gr.Markdown(\"## ğŸ§  Customer Support Tone Checker (ÙØ§Ø±Ø³ÛŒ)\")\n",
        "        gr.Markdown(\"Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù…ØªÙ† Ù…Ø´ØªØ±ÛŒ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ØŒ ØªØ³Ú© Ùˆ Ù…Ø¯Ù„ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ Ùˆ Ù„Ø­Ù† Ø±Ø§ Ø¨Ø¨ÛŒÙ†ÛŒØ¯.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            task_dd = gr.Radio(task_options, value=\"Classification (Tone Detection)\", label=\"Task / Ù†ÙˆØ¹ Ú©Ø§Ø±\")\n",
        "            model_dd = gr.Dropdown(model_options, value=\"SVM (LinearSVC)\", label=\"Model / Ù†ÙˆØ¹ Ù…Ø¯Ù„\")\n",
        "\n",
        "        # Ø¨Ø®Ø´ API Key Ø¨Ø±Ø§ÛŒ HuggingFace\n",
        "        gr.Markdown(\"---\")\n",
        "        gr.Markdown(\"### ğŸ” HuggingFace API Key (Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¢Ù†Ù„Ø§ÛŒÙ† â€“ Ú©Ù„ÛŒØ¯ Ù…ÙˆÙ‚Øª Ùˆ Ù‚Ø§Ø¨Ù„â€ŒØ¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ)\")\n",
        "        with gr.Row():\n",
        "            hf_key_box = gr.Textbox(label=\"HuggingFace API Key\", type=\"password\", placeholder=\"ØªÙˆÚ©Ù† Ù…ÙˆÙ‚Øª Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯...\")\n",
        "            hf_key_btn = gr.Button(\"Update Key ğŸ”„\")\n",
        "        hf_key_status = gr.Markdown(\"ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒØ¯: Ù‡Ù†ÙˆØ² ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.\")\n",
        "\n",
        "        # ÙˆØ±ÙˆØ¯ÛŒ Ù…ØªÙ† Ùˆ Ø®Ø±ÙˆØ¬ÛŒ\n",
        "        gr.Markdown(\"---\")\n",
        "        user_text = gr.Textbox(lines=4, label=\"Ù…ØªÙ† Ù¾ÛŒØ§Ù… Ù…Ø´ØªØ±ÛŒ (ÙØ§Ø±Ø³ÛŒ)\", placeholder=\"Ù…Ø«Ø§Ù„: Ø³Ù„Ø§Ù… ÙˆÙ‚Øª Ø¨Ø®ÛŒØ±ØŒ Ù…ÛŒØ´Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø³ÙØ§Ø±Ø´Ù… Ø±Ùˆ Ø¨Ú¯ÛŒØ¯ØŸ\")\n",
        "        run_btn = gr.Button(\"ØªØ´Ø®ÛŒØµ Ù„Ø­Ù† ğŸš€\")\n",
        "        output_box = gr.Textbox(label=\"Ù†ØªÛŒØ¬Ù‡\", lines=5)\n",
        "\n",
        "        # Ø±ÙˆÛŒØ¯Ø§Ø¯ Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§\n",
        "        def go_next():\n",
        "            return gr.update(visible=False), gr.update(visible=True)\n",
        "\n",
        "        btn_next.click(fn=go_next, inputs=None, outputs=[page1, page2])\n",
        "\n",
        "        hf_key_btn.click(\n",
        "            fn=set_hf_key,\n",
        "            inputs=hf_key_box,\n",
        "            outputs=hf_key_status\n",
        "        )\n",
        "\n",
        "        run_btn.click(\n",
        "            fn=gradio_predict,\n",
        "            inputs=[user_text, task_dd, model_dd],\n",
        "            outputs=output_box\n",
        "        )\n",
        "\n",
        "demo.launch(share=False)"
      ],
      "metadata": {
        "id": "GK2s6mTYsGhB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}